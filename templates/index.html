<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BOSOM AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <style>
        body { font-family: 'Inter', sans-serif; }
        .pulse { box-shadow: 0 0 0 0 rgba(96, 165, 250, 0.7); animation: pulse-animation 2s infinite; }
        @keyframes pulse-animation {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(96, 165, 250, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 10px rgba(96, 165, 250, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(96, 165, 250, 0); }
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex items-center justify-center min-h-screen">
    <div class="w-full max-w-md mx-auto p-8 rounded-2xl shadow-2xl bg-gray-800 border border-gray-700 text-center">
        <header class="mb-8">
            <h1 class="text-4xl font-bold text-blue-400">BOSOM AI</h1>
            <p class="text-gray-400 mt-2">Your Personal AI Assistant</p>
        </header>
        <main>
            <div id="status-container" class="mb-6 p-4 bg-gray-700 rounded-lg min-h-[4rem] flex flex-col items-center justify-center">
                <p id="status-text" class="text-lg text-gray-300">Ready to assist!</p>
                <p id="user-speech-text" class="text-sm text-gray-400 mt-1"></p>
            </div>
            <!-- Built-in Commands Section -->
            <div class="mb-6 p-4 bg-gray-700 rounded-lg">
                <h3 class="text-lg font-semibold text-blue-300 mb-2">Built-in Commands (Say them aloud):</h3>
                <ul class="text-sm text-gray-300 space-y-1">
                    <li>• "Search Wikipedia for [topic]"</li>
                    <li>• "Open YouTube"</li>
                    <li>• "Open Google"</li>
                    <li>• "Play music"</li>
                    <li>• "What is the time?"</li>
                    <li>• "Open camera"</li>
                    <li>• "Quit" or "Stop listening"</li>
                </ul>
                <p class="text-xs text-gray-500 mt-2">For other queries, BOSOM will use AI to respond.</p>
            </div>
            <div class="mb-4">
                <button id="start-button" class="bg-blue-500 hover:bg-blue-600 text-white font-bold rounded-full w-32 h-32 flex items-center justify-center transition-transform transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                </button>
            </div>
            <!-- Debug Button -->
            <button id="test-tts" class="bg-green-500 hover:bg-green-600 text-white px-4 py-2 rounded">Test TTS</button>
        </main>
        <footer class="mt-12">
            <p class="text-xs text-gray-500">Say "quit" to stop. Powered by BOSOM & Gemini.</p>
        </footer>
    </div>
    <script>
        const startButton = document.getElementById('start-button');
        const testTTSButton = document.getElementById('test-tts');
        const statusText = document.getElementById('status-text');
        const userSpeechText = document.getElementById('user-speech-text');
        const socket = io.connect(window.location.origin);
        let recognition;
        let isAISpeaking = false;
        let streamedResponse = "";

        socket.on('connect', () => {
            console.log('Connected to BOSOM!');
        });

        socket.on('status_update', (data) => {
            statusText.textContent = data.message;
            console.log('Status update:', data.message);
        });

        socket.on('user_speech', (data) => {
            userSpeechText.textContent = data.message;
            console.log('User speech:', data.message);
        });

        socket.on('final_response', (data) => {
            statusText.textContent = data.message;
            userSpeechText.textContent = '';
            console.log('Final response:', data.message);
            speakInBrowser(data.message);
        });

        socket.on('stream_response_chunk', (data) => {
            streamedResponse += data.chunk;
            statusText.textContent = streamedResponse;
            console.log('Stream chunk:', data.chunk);
        });

        socket.on('stream_end', (data) => {
            const fullMessage = data.full_message || streamedResponse;
            statusText.textContent = fullMessage;
            userSpeechText.textContent = '';
            console.log('Stream end:', fullMessage);
            speakInBrowser(fullMessage);
            streamedResponse = "";
        });

        socket.on('start_listening', () => {
            console.log('Starting listening...');
            startListening();
        });

        function startListening() {
            if (!('webkitSpeechRecognition' in window)) {
                alert('Speech recognition not supported in this browser.');
                return;
            }
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                statusText.textContent = 'BOSOM: Listening...';
                startButton.disabled = true;
                startButton.classList.add('pulse');
            };

            recognition.onresult = (event) => {
                const query = event.results[0][0].transcript;
                console.log('Recognized:', query);
                socket.emit('speech_recognized', { query: query });
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                statusText.textContent = 'BOSOM: Speech recognition error. Retrying...';
                setTimeout(() => socket.emit('start_listening'), 1000);
            };

            recognition.onend = () => {
                startButton.disabled = false;
                startButton.classList.remove('pulse');
            };

            recognition.start();
        }

        function speakInBrowser(text) {
            console.log('Attempting to speak:', text);
            if ('speechSynthesis' in window) {
                const voices = speechSynthesis.getVoices();
                console.log('Available voices:', voices.length);
                if (voices.length === 0) {
                    speechSynthesis.onvoiceschanged = () => {
                        console.log('Voices loaded');
                        speakText(text);
                    };
                } else {
                    speakText(text);
                }
            } else {
                console.log('Speech synthesis not supported.');
                alert('TTS not supported in this browser.');
            }
        }

        function speakText(text) {
            isAISpeaking = true;
            statusText.textContent = 'BOSOM is speaking...';
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.rate = 1;  // Speed
            utterance.pitch = 1;  // Pitch
            utterance.volume = 1;  // Volume

            utterance.onstart = () => console.log('TTS started');
            utterance.onend = () => {
                console.log('TTS ended');
                isAISpeaking = false;
                statusText.textContent = 'BOSOM: Listening...';
            };
            utterance.onerror = (e) => {
                console.error('TTS error:', e);
                isAISpeaking = false;
                statusText.textContent = 'TTS error. Responses shown in text.';
            };

            speechSynthesis.speak(utterance);
        }

        startButton.addEventListener('click', () => {
            if (!isAISpeaking) {
                socket.emit('start_listening');
            }
        });

        // Test TTS Button
        testTTSButton.addEventListener('click', () => {
            speakInBrowser('Hello, this is BOSOM testing TTS.');
        });
    </script>
</body>
</html>
